{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from nltk.corpus import wordnet\n",
    "import nltk\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=[\"ner\", \"parser\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_synonym(word):\n",
    "    synonyms = []\n",
    "    for syn in wordnet.synsets(word, pos=wordnet.ADJ):\n",
    "        for lemma in syn.lemmas():\n",
    "            # Αποφεύγουμε το ίδιο το αρχικό λέξη\n",
    "            if lemma.name().lower() != word.lower():\n",
    "                synonyms.append(lemma.name().replace('_', ' '))\n",
    "    if synonyms:\n",
    "        return synonyms[0]  # Παίρνουμε το πρώτο συνώνυμο\n",
    "    else:\n",
    "        return word  # Αν δεν βρεθεί συνώνυμο, επιστρέφουμε την ίδια λέξη"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_adjectives(sentence):\n",
    "    doc = nlp(sentence)\n",
    "    new_tokens = []\n",
    "    for token in doc:\n",
    "        if token.pos_ == \"ADJ\":\n",
    "            new_word = get_synonym(token.text)\n",
    "            new_tokens.append(new_word)\n",
    "        else:\n",
    "            new_tokens.append(token.text)\n",
    "    return \" \".join(new_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: Overall, let us make sure all are safe and celebrate the outcome with strong coffee and future targets Today is our dragon boat festival, in our Chinese culture, to celebrate it with all safe and great in our lives\n",
      "Modified: Overall , let us make certain all are dependable and celebrate the outcome with potent coffee and next targets Today is our dragon boat festival , in our Taiwanese culture , to celebrate it with all dependable and outstanding in our lives\n"
     ]
    }
   ],
   "source": [
    "sentence1 = \"Overall, let us make sure all are safe and celebrate the outcome with strong coffee and future targets\" \n",
    "sentence2 = \"Today is our dragon boat festival, in our Chinese culture, to celebrate it with all safe and great in our lives\"\n",
    "new_sentence1 = replace_adjectives(sentence1)\n",
    "new_sentence2 = replace_adjectives(sentence2)\n",
    "print(\"Original:\", sentence1, sentence2)\n",
    "print(\"Modified:\", new_sentence1, new_sentence2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ΕΡΩΤΗΜΑ 2\n",
    "1ος τροπος "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import pipeline\n",
    "\n",
    "from sentence_splitter import SentenceSplitter\n",
    "splitter = SentenceSplitter(language='en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at tuner007/pegasus_paraphrase and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "paraphrase_Pegasus_pipeline = pipeline(\"text2text-generation\", model=\"tuner007/pegasus_paraphrase\", device=0 if torch.cuda.is_available() else -1)\n",
    "\n",
    "text1 = \"Today is our dragon boat festival, in our Chinese culture, to celebrate it with all safe and great in our lives. Hope you too, to enjoy it as my deepest wishes. Thank your message to show our words to the doctor, as his next contract checking, to all of us. I got this message to see the approved message. In fact, I have received the message from the professor, to show me, this, a couple of days ago. I am very appreciated the full support of the professor, for our Springer proceedings publication.\"\n",
    "\n",
    "text2 = \"“During our final discuss, I told him about the new submission — the one we were waiting since last autumn, but the updates was confusing as it not included the full feedback from reviewer or maybe editor? Anyway, I believe the team, although bit delay and less communication at recent days, they really tried best for paper and cooperation. We should be grateful, I mean all of us, for the acceptance and efforts until the Springer link came finally last week, I think. Also, kindly remind me please, if the doctor still plan for the acknowledgments section edit before he sending again. Because I didn’t see that part final yet, or maybe I missed, I apologize if so. Overall, let us make sure all are safe and celebrate the outcome with strong coffee and future targets\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our Chinese culture has a dragon boat festival that is celebrated today. Hope you enjoy it as much as I did. Your message was appreciated by the doctor, as his next contract check, to all of us. I saw the approved message after getting this message. I received the message from the professor a couple of days ago. The professor supported the Springer proceedings publication.\n",
      "I told him about the new submission we were waiting for, but the updates were confusing as they didn't include the full feedback from the reviewer or editor. I think the team tried their best for paper and cooperation despite the recent delay and less communication. We should be thankful for the acceptance and efforts until the Springer link came last week, I think. If the doctor still plans for the acknowledgments section to be edited before he sends again, please remind me. I apologize if I missed that part final. Let's make sure all are safe and celebrate the outcome with coffee and targets.\n"
     ]
    }
   ],
   "source": [
    "splitter = SentenceSplitter(language='en')\n",
    "sentence_list1 = splitter.split(text1)\n",
    "sentence_list2 = splitter.split(text2)\n",
    "\n",
    "paraphrased_sentences1 = paraphrase_Pegasus_pipeline(sentence_list1, max_length=60, num_return_sequences=1)\n",
    "paraphrased_sentences2 = paraphrase_Pegasus_pipeline(sentence_list2, max_length=60, num_return_sequences=1)\n",
    "paraphrased_text1_model1 = \" \".join([result['generated_text'] for result in paraphrased_sentences1])\n",
    "paraphrased_text2_model1 = \" \".join([result['generated_text'] for result in paraphrased_sentences2])\n",
    "\n",
    "print(paraphrased_text1_model1)\n",
    "print(paraphrased_text2_model1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text:\n",
      " Today is our dragon boat festival, in our Chinese culture, to celebrate it with all safe and great in our lives. Hope you too, to enjoy it as my deepest wishes. Thank your message to show our words to the doctor, as his next contract checking, to all of us. I got this message to see the approved message. In fact, I have received the message from the professor, to show me, this, a couple of days ago. I am very appreciated the full support of the professor, for our Springer proceedings publication. “During our final discuss, I told him about the new submission — the one we were waiting since last autumn, but the updates was confusing as it not included the full feedback from reviewer or maybe editor? Anyway, I believe the team, although bit delay and less communication at recent days, they really tried best for paper and cooperation. We should be grateful, I mean all of us, for the acceptance and efforts until the Springer link came finally last week, I think. Also, kindly remind me please, if the doctor still plan for the acknowledgments section edit before he sending again. Because I didn’t see that part final yet, or maybe I missed, I apologize if so. Overall, let us make sure all are safe and celebrate the outcome with strong coffee and future targets\n",
      "\n",
      "Paraphrased Text:\n",
      " Today is our dragon boat festival, in our Chinese culture, to celebrate it with all safe and great in our lives. Thank your message to show our words to the doctor, as his next contract checking, a couple of days ago. I am very appreciated the full support of the professor, for our Springer proceedings publication. I got this message to see the approved message. Hope you too, to enjoy it as my deepest wishes, said Mr. Wang, the chairman of the committee. ``. During our final discuss, I told him about the new submission -- the one we were waiting since last autumn, but the updates was confusing as it not included the full feedback from the reviewer or maybe editor. We should be grateful, I mean all of us, for the acceptance and efforts until the Springer link came finally last week, I apologize if so. Because I didn’t see that part final yet, or maybe I missed, they really tried best for paper and cooperation. Also, kindly remind me please, if the doctor still plan for the acknowledgments section edit before he sending again.\n"
     ]
    }
   ],
   "source": [
    "model_name2 = \"eugenesiow/bart-paraphrase\"\n",
    "\n",
    "paraphrase_pipeline2 = pipeline(\n",
    "    \"text2text-generation\", \n",
    "    model=model_name2, \n",
    "    device=0 if torch.cuda.is_available() else -1\n",
    ")\n",
    "paraphrased_text1_model2 = paraphrase_pipeline2(\n",
    "    text1, \n",
    "    max_length=300, \n",
    "    min_length=100, \n",
    "    num_return_sequences=1, \n",
    "    no_repeat_ngram_size=3 , \n",
    "    do_sample=False\n",
    ")[0]['generated_text']\n",
    "paraphrased_text2_model2 = paraphrase_pipeline2(\n",
    "    text2, \n",
    "    max_length=300, \n",
    "    min_length=100, \n",
    "    num_return_sequences=1, \n",
    "    no_repeat_ngram_size=3 , \n",
    "    do_sample=False\n",
    ")[0]['generated_text']\n",
    "print(\"Original Text:\\n\", text1,text2)\n",
    "print(\"\\nParaphrased Text:\\n\", paraphrased_text1_model2,paraphrased_text2_model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_name3 = \"google/flan-t5-large\"\n",
    "\n",
    "# Δημιουργία pipeline αναδιατύπωσης\n",
    "paraphrase_pipeline = pipeline(\n",
    "    \"text2text-generation\", \n",
    "    model=model_name3, \n",
    "    device=0 if torch.cuda.is_available() else -1\n",
    ")\n",
    "\n",
    "\n",
    "# Αναδιατύπωση χωρίς split προτάσεων\n",
    "paraphrased_text1_model3 = paraphrase_pipeline(\n",
    "    text1, \n",
    "    max_length=300, \n",
    "    min_length=100, \n",
    "    num_return_sequences=1, \n",
    "    no_repeat_ngram_size=3 , \n",
    "    do_sample=False\n",
    ")[0]['generated_text']\n",
    "paraphrased_text2_model3 = paraphrase_pipeline(\n",
    "    text2, \n",
    "    max_length=300, \n",
    "    min_length=100, \n",
    "    num_return_sequences=1, \n",
    "    no_repeat_ngram_size=3 , \n",
    "    do_sample=False\n",
    ")[0]['generated_text']\n",
    "\n",
    "print(\"Original Text:\\n\", text1)\n",
    "print(\"\\nParaphrased Text:\\n\", paraphrased_text1_model3,paraphrased_text2_model3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERTScore: {'precision': [1.0, 0.9319190979003906], 'recall': [1.0, 0.900460958480835], 'f1': [1.0, 0.9159199595451355], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.51.3)'}\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "import evaluate\n",
    "# Αρχικά και αναδιατυπωμένα κείμενα\n",
    "# original_text = \"Today is our dragon boat festival, in our Chinese culture, to celebrate it with all safe and great in our lives.\"\n",
    "# rephrased_text_1 = \"We celebrate our dragon boat festival today, ensuring safety and happiness in our Chinese culture.\"\n",
    "# rephrased_text_2 = \"In our Chinese culture, today is the dragon boat festival, celebrating it with safety and joy.\"\n",
    "\n",
    "# Χρήση BERTScore\n",
    "bertscore = evaluate.load(\"bertscore\")\n",
    "results = bertscore.compute(predictions=[paraphrased_text1, paraphrased_text2], references=[paraphrased_text1, text2], lang=\"en\")\n",
    "\n",
    "print(\"BERTScore:\", results)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
